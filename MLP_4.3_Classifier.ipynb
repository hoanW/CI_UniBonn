{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating training dataset and testing dataset\n",
    "each dataset contains an input dataset and an output dataset <br/>\n",
    "input dataset is an (1000, 16)-shaped array  <br/>\n",
    "output dataset is an (1000, 9)-shaped array  <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_dataset():\n",
    "    input1 = np.random.randint(2, size=(1000,8)) \n",
    "    input2 = np.random.randint(2, size=(1000,8))\n",
    "    #convert input dataset from binary list to decimal\n",
    "    a = input1 @ (1 << np.arange(input1.shape[1] - 1, -1, -1))\n",
    "    b = input2 @ (1 << np.arange(input2.shape[1] - 1, -1, -1))\n",
    "    input_set = np.hstack((input1, input2))\n",
    "    #calculate ouptut dataset in decimal\n",
    "    decimal_set = a + b\n",
    "    #covert output dataset from decimal to binary list\n",
    "    output_set = list()\n",
    "    for decimal in decimal_set:\n",
    "        m =  [int(i) for i in list('{0:b}'.format(decimal))]\n",
    "        if len(m) == 1:\n",
    "            m = [0,0,0,0,0,0,0,0] + m\n",
    "        elif len(m) == 2: \n",
    "            m = [0,0,0,0,0,0,0] + m\n",
    "        elif len(m) == 3:\n",
    "            m = [0,0,0,0,0,0] + m\n",
    "        elif len(m) == 4:\n",
    "            m = [0,0,0,0,0] + m\n",
    "        elif len(m) == 5:\n",
    "            m = [0,0,0,0] + m\n",
    "        elif len(m) == 6:\n",
    "            m = [0,0,0] + m\n",
    "        elif len(m) == 7:\n",
    "            m = [0,0] + m\n",
    "        elif len(m) == 8:\n",
    "            m = [0] + m\n",
    "        else:\n",
    "            m = m\n",
    "        output_set.append(m)\n",
    "    return input_set, np.array(output_set)\n",
    "\n",
    "input_training_set, output_training_set = create_binary_dataset()\n",
    "input_testing_set, output_testing_set = create_binary_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model\n",
    "The model has 4 layers  <br/>\n",
    "input layer has 16 units  <br/>\n",
    "2 hidden layers, each has 12 units  <br/>\n",
    "output layer has 9 units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=12, activation = 'relu', input_dim=16, kernel_initializer='uniform'))\n",
    "model.add(Dense(units=12, activation = 'relu', kernel_initializer='uniform'))\n",
    "model.add(Dense(units=9, activation = 'hard_sigmoid' , kernel_initializer='zero'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import rmsprop\n",
    "model.compile(optimizer = \"adam\", loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "regularization : early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "1000/1000 [==============================] - 0s 230us/step - loss: 0.2500 - accuracy: 0.0500 - val_loss: 0.2500 - val_accuracy: 0.0080\n",
      "Epoch 2/1000\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.2499 - accuracy: 0.0070 - val_loss: 0.2500 - val_accuracy: 0.0080\n",
      "Epoch 3/1000\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.2498 - accuracy: 0.0070 - val_loss: 0.2498 - val_accuracy: 0.0080\n",
      "Epoch 4/1000\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.2493 - accuracy: 0.0990 - val_loss: 0.2493 - val_accuracy: 0.1720\n",
      "Epoch 5/1000\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 0.2483 - accuracy: 0.1820 - val_loss: 0.2483 - val_accuracy: 0.2840\n",
      "Epoch 6/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2465 - accuracy: 0.3260 - val_loss: 0.2466 - val_accuracy: 0.2510\n",
      "Epoch 7/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2440 - accuracy: 0.3570 - val_loss: 0.2443 - val_accuracy: 0.3340\n",
      "Epoch 8/1000\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.2411 - accuracy: 0.3800 - val_loss: 0.2419 - val_accuracy: 0.3680\n",
      "Epoch 9/1000\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.2382 - accuracy: 0.3940 - val_loss: 0.2394 - val_accuracy: 0.3940\n",
      "Epoch 10/1000\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.2358 - accuracy: 0.4250 - val_loss: 0.2376 - val_accuracy: 0.3930\n",
      "Epoch 11/1000\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.2343 - accuracy: 0.4360 - val_loss: 0.2361 - val_accuracy: 0.4110\n",
      "Epoch 12/1000\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.2333 - accuracy: 0.4220 - val_loss: 0.2352 - val_accuracy: 0.4140\n",
      "Epoch 13/1000\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.2325 - accuracy: 0.4460 - val_loss: 0.2344 - val_accuracy: 0.4270\n",
      "Epoch 14/1000\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.2318 - accuracy: 0.4360 - val_loss: 0.2337 - val_accuracy: 0.4360\n",
      "Epoch 15/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2314 - accuracy: 0.4480 - val_loss: 0.2332 - val_accuracy: 0.4220\n",
      "Epoch 16/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2308 - accuracy: 0.4540 - val_loss: 0.2326 - val_accuracy: 0.4220\n",
      "Epoch 17/1000\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.2303 - accuracy: 0.4590 - val_loss: 0.2320 - val_accuracy: 0.4270\n",
      "Epoch 18/1000\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.2299 - accuracy: 0.4580 - val_loss: 0.2317 - val_accuracy: 0.4230\n",
      "Epoch 19/1000\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.2295 - accuracy: 0.4530 - val_loss: 0.2311 - val_accuracy: 0.4400\n",
      "Epoch 20/1000\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.2290 - accuracy: 0.4650 - val_loss: 0.2306 - val_accuracy: 0.4530\n",
      "Epoch 21/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2286 - accuracy: 0.4700 - val_loss: 0.2302 - val_accuracy: 0.4480\n",
      "Epoch 22/1000\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.2282 - accuracy: 0.4710 - val_loss: 0.2298 - val_accuracy: 0.4510\n",
      "Epoch 23/1000\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 0.2279 - accuracy: 0.4750 - val_loss: 0.2295 - val_accuracy: 0.4520\n",
      "Epoch 24/1000\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.2276 - accuracy: 0.4770 - val_loss: 0.2298 - val_accuracy: 0.4090\n",
      "Epoch 25/1000\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.2274 - accuracy: 0.4660 - val_loss: 0.2288 - val_accuracy: 0.4550\n",
      "Epoch 26/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2270 - accuracy: 0.4800 - val_loss: 0.2286 - val_accuracy: 0.4480\n",
      "Epoch 27/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 0.2267 - accuracy: 0.4770 - val_loss: 0.2283 - val_accuracy: 0.4570\n",
      "Epoch 28/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 0.2265 - accuracy: 0.4890 - val_loss: 0.2287 - val_accuracy: 0.4200\n",
      "Epoch 29/1000\n",
      "1000/1000 [==============================] - 0s 120us/step - loss: 0.2264 - accuracy: 0.4760 - val_loss: 0.2279 - val_accuracy: 0.4530\n",
      "Epoch 30/1000\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.2260 - accuracy: 0.4840 - val_loss: 0.2276 - val_accuracy: 0.4600\n",
      "Epoch 31/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 0.2259 - accuracy: 0.4840 - val_loss: 0.2275 - val_accuracy: 0.4620\n",
      "Epoch 32/1000\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 0.2257 - accuracy: 0.4830 - val_loss: 0.2275 - val_accuracy: 0.4420\n",
      "Epoch 33/1000\n",
      "1000/1000 [==============================] - 0s 106us/step - loss: 0.2254 - accuracy: 0.4870 - val_loss: 0.2272 - val_accuracy: 0.4450\n",
      "Epoch 34/1000\n",
      "1000/1000 [==============================] - 0s 101us/step - loss: 0.2253 - accuracy: 0.4830 - val_loss: 0.2271 - val_accuracy: 0.4450\n",
      "Epoch 35/1000\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.2252 - accuracy: 0.4880 - val_loss: 0.2273 - val_accuracy: 0.4330\n",
      "Epoch 36/1000\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.2251 - accuracy: 0.5160 - val_loss: 0.2270 - val_accuracy: 0.5360\n",
      "Epoch 37/1000\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 0.2251 - accuracy: 0.4960 - val_loss: 0.2266 - val_accuracy: 0.4650\n",
      "Epoch 38/1000\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 0.2247 - accuracy: 0.5510 - val_loss: 0.2265 - val_accuracy: 0.5950\n",
      "Epoch 39/1000\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 0.2247 - accuracy: 0.5480 - val_loss: 0.2265 - val_accuracy: 0.4440\n",
      "Epoch 40/1000\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.2247 - accuracy: 0.5610 - val_loss: 0.2266 - val_accuracy: 0.5920\n",
      "Epoch 41/1000\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 0.2245 - accuracy: 0.5200 - val_loss: 0.2266 - val_accuracy: 0.4290\n",
      "Epoch 42/1000\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 0.2243 - accuracy: 0.5360 - val_loss: 0.2261 - val_accuracy: 0.5470\n",
      "Epoch 43/1000\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 0.2243 - accuracy: 0.4900 - val_loss: 0.2261 - val_accuracy: 0.4700\n",
      "Epoch 44/1000\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.2241 - accuracy: 0.5610 - val_loss: 0.2260 - val_accuracy: 0.5910\n",
      "Epoch 45/1000\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.2240 - accuracy: 0.6810 - val_loss: 0.2258 - val_accuracy: 0.6740\n",
      "Epoch 46/1000\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.2239 - accuracy: 0.5980 - val_loss: 0.2257 - val_accuracy: 0.4540\n",
      "Epoch 47/1000\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 0.2239 - accuracy: 0.4820 - val_loss: 0.2256 - val_accuracy: 0.4800\n",
      "Epoch 48/1000\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.2238 - accuracy: 0.6660 - val_loss: 0.2255 - val_accuracy: 0.6830\n",
      "Epoch 49/1000\n",
      "1000/1000 [==============================] - 0s 119us/step - loss: 0.2237 - accuracy: 0.6740 - val_loss: 0.2254 - val_accuracy: 0.5620\n",
      "Epoch 50/1000\n",
      "1000/1000 [==============================] - 0s 110us/step - loss: 0.2235 - accuracy: 0.5790 - val_loss: 0.2258 - val_accuracy: 0.5150\n",
      "Epoch 51/1000\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.2235 - accuracy: 0.5700 - val_loss: 0.2254 - val_accuracy: 0.6000\n",
      "Epoch 52/1000\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.2233 - accuracy: 0.6810 - val_loss: 0.2251 - val_accuracy: 0.6820\n",
      "Epoch 53/1000\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 0.2233 - accuracy: 0.7040 - val_loss: 0.2251 - val_accuracy: 0.6940\n",
      "Epoch 54/1000\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.2232 - accuracy: 0.6980 - val_loss: 0.2249 - val_accuracy: 0.6560\n",
      "Epoch 55/1000\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.2231 - accuracy: 0.6910 - val_loss: 0.2250 - val_accuracy: 0.6850\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.2231 - accuracy: 0.6160 - val_loss: 0.2247 - val_accuracy: 0.5840\n",
      "Epoch 57/1000\n",
      "1000/1000 [==============================] - 0s 107us/step - loss: 0.2228 - accuracy: 0.6760 - val_loss: 0.2247 - val_accuracy: 0.7550\n",
      "Epoch 58/1000\n",
      "1000/1000 [==============================] - 0s 98us/step - loss: 0.2227 - accuracy: 0.8090 - val_loss: 0.2246 - val_accuracy: 0.7890\n",
      "Epoch 59/1000\n",
      "1000/1000 [==============================] - 0s 112us/step - loss: 0.2227 - accuracy: 0.7770 - val_loss: 0.2245 - val_accuracy: 0.7360\n",
      "Epoch 60/1000\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.2226 - accuracy: 0.7040 - val_loss: 0.2244 - val_accuracy: 0.6560\n",
      "Epoch 61/1000\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 0.2225 - accuracy: 0.7340 - val_loss: 0.2242 - val_accuracy: 0.7260\n",
      "Epoch 62/1000\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.2224 - accuracy: 0.7580 - val_loss: 0.2241 - val_accuracy: 0.7270\n",
      "Epoch 63/1000\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 0.2222 - accuracy: 0.7740 - val_loss: 0.2240 - val_accuracy: 0.7710\n",
      "Epoch 64/1000\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.2223 - accuracy: 0.7770 - val_loss: 0.2239 - val_accuracy: 0.7840\n",
      "Epoch 65/1000\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 0.2221 - accuracy: 0.7600 - val_loss: 0.2241 - val_accuracy: 0.7370\n",
      "Epoch 66/1000\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.2219 - accuracy: 0.7720 - val_loss: 0.2238 - val_accuracy: 0.7720\n",
      "Epoch 67/1000\n",
      "1000/1000 [==============================] - 0s 131us/step - loss: 0.2218 - accuracy: 0.8130 - val_loss: 0.2237 - val_accuracy: 0.8080\n",
      "Epoch 68/1000\n",
      "1000/1000 [==============================] - 0s 115us/step - loss: 0.2218 - accuracy: 0.7550 - val_loss: 0.2238 - val_accuracy: 0.7210\n",
      "Epoch 69/1000\n",
      "1000/1000 [==============================] - 0s 101us/step - loss: 0.2216 - accuracy: 0.8270 - val_loss: 0.2234 - val_accuracy: 0.8220\n",
      "Epoch 70/1000\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.2215 - accuracy: 0.8220 - val_loss: 0.2236 - val_accuracy: 0.7700\n",
      "Epoch 71/1000\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 0.2214 - accuracy: 0.7840 - val_loss: 0.2233 - val_accuracy: 0.7900\n",
      "Epoch 72/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2212 - accuracy: 0.8190 - val_loss: 0.2231 - val_accuracy: 0.8050\n",
      "Epoch 73/1000\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 0.2212 - accuracy: 0.8120 - val_loss: 0.2231 - val_accuracy: 0.7760\n",
      "Epoch 74/1000\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.2211 - accuracy: 0.8450 - val_loss: 0.2231 - val_accuracy: 0.8460\n",
      "Epoch 75/1000\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.2211 - accuracy: 0.8660 - val_loss: 0.2227 - val_accuracy: 0.8230\n",
      "Epoch 76/1000\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.2208 - accuracy: 0.8140 - val_loss: 0.2228 - val_accuracy: 0.7880\n",
      "Epoch 77/1000\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.2208 - accuracy: 0.8400 - val_loss: 0.2228 - val_accuracy: 0.8140\n",
      "Epoch 78/1000\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 0.2206 - accuracy: 0.8300 - val_loss: 0.2226 - val_accuracy: 0.7990\n",
      "Epoch 79/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2206 - accuracy: 0.8330 - val_loss: 0.2223 - val_accuracy: 0.8180\n",
      "Epoch 80/1000\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.2204 - accuracy: 0.8450 - val_loss: 0.2223 - val_accuracy: 0.8010\n",
      "Epoch 81/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2202 - accuracy: 0.8150 - val_loss: 0.2220 - val_accuracy: 0.7880\n",
      "Epoch 82/1000\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 0.2201 - accuracy: 0.8140 - val_loss: 0.2219 - val_accuracy: 0.8050\n",
      "Epoch 83/1000\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.2199 - accuracy: 0.8240 - val_loss: 0.2219 - val_accuracy: 0.8180\n",
      "Epoch 84/1000\n",
      "1000/1000 [==============================] - 0s 106us/step - loss: 0.2198 - accuracy: 0.8380 - val_loss: 0.2217 - val_accuracy: 0.8110\n",
      "Epoch 85/1000\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: 0.2198 - accuracy: 0.8580 - val_loss: 0.2215 - val_accuracy: 0.8370\n",
      "Epoch 86/1000\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.2196 - accuracy: 0.8260 - val_loss: 0.2217 - val_accuracy: 0.7800\n",
      "Epoch 87/1000\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.2196 - accuracy: 0.8130 - val_loss: 0.2220 - val_accuracy: 0.7950\n",
      "Epoch 88/1000\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 0.2195 - accuracy: 0.8680 - val_loss: 0.2212 - val_accuracy: 0.8400\n",
      "Epoch 89/1000\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.2193 - accuracy: 0.8240 - val_loss: 0.2214 - val_accuracy: 0.7930\n",
      "Epoch 90/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2191 - accuracy: 0.8370 - val_loss: 0.2213 - val_accuracy: 0.7870\n",
      "Epoch 91/1000\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.2189 - accuracy: 0.8400 - val_loss: 0.2209 - val_accuracy: 0.8070\n",
      "Epoch 92/1000\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.2189 - accuracy: 0.8540 - val_loss: 0.2207 - val_accuracy: 0.8410\n",
      "Epoch 93/1000\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.2189 - accuracy: 0.8430 - val_loss: 0.2205 - val_accuracy: 0.7960\n",
      "Epoch 94/1000\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.2185 - accuracy: 0.8370 - val_loss: 0.2206 - val_accuracy: 0.8110\n",
      "Epoch 95/1000\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.2187 - accuracy: 0.8560 - val_loss: 0.2202 - val_accuracy: 0.8290\n",
      "Epoch 96/1000\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.2183 - accuracy: 0.8470 - val_loss: 0.2203 - val_accuracy: 0.8120\n",
      "Epoch 97/1000\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.2182 - accuracy: 0.8540 - val_loss: 0.2205 - val_accuracy: 0.8170\n",
      "Epoch 98/1000\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: 0.2182 - accuracy: 0.8490 - val_loss: 0.2200 - val_accuracy: 0.8120\n",
      "Epoch 99/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.2177 - accuracy: 0.8350 - val_loss: 0.2200 - val_accuracy: 0.8100\n",
      "Epoch 100/1000\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.2177 - accuracy: 0.8500 - val_loss: 0.2196 - val_accuracy: 0.8360\n",
      "Epoch 101/1000\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.2175 - accuracy: 0.8610 - val_loss: 0.2196 - val_accuracy: 0.8170\n",
      "Epoch 102/1000\n",
      "1000/1000 [==============================] - 0s 116us/step - loss: 0.2174 - accuracy: 0.8400 - val_loss: 0.2193 - val_accuracy: 0.8250\n",
      "Epoch 103/1000\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.2173 - accuracy: 0.8650 - val_loss: 0.2196 - val_accuracy: 0.8320\n",
      "Epoch 104/1000\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.2169 - accuracy: 0.8630 - val_loss: 0.2191 - val_accuracy: 0.8200\n",
      "Epoch 105/1000\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.2169 - accuracy: 0.8370 - val_loss: 0.2190 - val_accuracy: 0.8180\n",
      "Epoch 106/1000\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.2167 - accuracy: 0.8490 - val_loss: 0.2189 - val_accuracy: 0.8290\n",
      "Epoch 107/1000\n",
      "1000/1000 [==============================] - 0s 97us/step - loss: 0.2164 - accuracy: 0.8490 - val_loss: 0.2186 - val_accuracy: 0.8290\n",
      "Epoch 108/1000\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.2163 - accuracy: 0.8580 - val_loss: 0.2184 - val_accuracy: 0.8240\n",
      "Epoch 109/1000\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 0.2163 - accuracy: 0.8550 - val_loss: 0.2183 - val_accuracy: 0.8390\n",
      "Epoch 110/1000\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.2160 - accuracy: 0.8630 - val_loss: 0.2180 - val_accuracy: 0.8240\n",
      "Epoch 111/1000\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.2158 - accuracy: 0.8640 - val_loss: 0.2178 - val_accuracy: 0.8430\n",
      "Epoch 112/1000\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.2156 - accuracy: 0.8500 - val_loss: 0.2178 - val_accuracy: 0.8170\n",
      "Epoch 113/1000\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.2155 - accuracy: 0.8580 - val_loss: 0.2175 - val_accuracy: 0.8400\n",
      "Epoch 114/1000\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.2154 - accuracy: 0.8500 - val_loss: 0.2174 - val_accuracy: 0.8320\n",
      "Epoch 115/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2151 - accuracy: 0.8670 - val_loss: 0.2175 - val_accuracy: 0.8280\n",
      "Epoch 116/1000\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 0.2148 - accuracy: 0.8570 - val_loss: 0.2170 - val_accuracy: 0.8320\n",
      "Epoch 117/1000\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 0.2147 - accuracy: 0.8500 - val_loss: 0.2169 - val_accuracy: 0.8320\n",
      "Epoch 118/1000\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.2144 - accuracy: 0.8640 - val_loss: 0.2167 - val_accuracy: 0.8350\n",
      "Epoch 119/1000\n",
      "1000/1000 [==============================] - 0s 97us/step - loss: 0.2143 - accuracy: 0.8600 - val_loss: 0.2165 - val_accuracy: 0.8320\n",
      "Epoch 120/1000\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.2141 - accuracy: 0.8600 - val_loss: 0.2165 - val_accuracy: 0.8390\n",
      "Epoch 121/1000\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.2141 - accuracy: 0.8580 - val_loss: 0.2164 - val_accuracy: 0.8410\n",
      "Epoch 122/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2139 - accuracy: 0.8640 - val_loss: 0.2160 - val_accuracy: 0.8310\n",
      "Epoch 123/1000\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.2135 - accuracy: 0.8580 - val_loss: 0.2158 - val_accuracy: 0.8350\n",
      "Epoch 124/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 0.2133 - accuracy: 0.8640 - val_loss: 0.2159 - val_accuracy: 0.8210\n",
      "Epoch 125/1000\n",
      "1000/1000 [==============================] - 0s 101us/step - loss: 0.2132 - accuracy: 0.8370 - val_loss: 0.2154 - val_accuracy: 0.8240\n",
      "Epoch 126/1000\n",
      "1000/1000 [==============================] - 0s 107us/step - loss: 0.2129 - accuracy: 0.8630 - val_loss: 0.2152 - val_accuracy: 0.8410\n",
      "Epoch 127/1000\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.2127 - accuracy: 0.8630 - val_loss: 0.2149 - val_accuracy: 0.8350\n",
      "Epoch 128/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 0.2126 - accuracy: 0.8640 - val_loss: 0.2147 - val_accuracy: 0.8460\n",
      "Epoch 129/1000\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.2122 - accuracy: 0.8690 - val_loss: 0.2146 - val_accuracy: 0.8370\n",
      "Epoch 130/1000\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.2120 - accuracy: 0.8590 - val_loss: 0.2145 - val_accuracy: 0.8280\n",
      "Epoch 131/1000\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 0.2118 - accuracy: 0.8600 - val_loss: 0.2144 - val_accuracy: 0.8370\n",
      "Epoch 132/1000\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.2116 - accuracy: 0.8640 - val_loss: 0.2140 - val_accuracy: 0.8430\n",
      "Epoch 133/1000\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.2114 - accuracy: 0.8590 - val_loss: 0.2140 - val_accuracy: 0.8350\n",
      "Epoch 134/1000\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 0.2112 - accuracy: 0.8640 - val_loss: 0.2138 - val_accuracy: 0.8410\n",
      "Epoch 135/1000\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.2109 - accuracy: 0.8680 - val_loss: 0.2134 - val_accuracy: 0.8400\n",
      "Epoch 136/1000\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.2107 - accuracy: 0.8680 - val_loss: 0.2133 - val_accuracy: 0.8410\n",
      "Epoch 137/1000\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.2105 - accuracy: 0.8690 - val_loss: 0.2131 - val_accuracy: 0.8490\n",
      "Epoch 138/1000\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.2102 - accuracy: 0.8750 - val_loss: 0.2128 - val_accuracy: 0.8340\n",
      "Epoch 139/1000\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.2101 - accuracy: 0.8630 - val_loss: 0.2126 - val_accuracy: 0.8440\n",
      "Epoch 140/1000\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 0.2098 - accuracy: 0.8710 - val_loss: 0.2123 - val_accuracy: 0.8390\n",
      "Epoch 141/1000\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.2095 - accuracy: 0.8720 - val_loss: 0.2124 - val_accuracy: 0.8360\n",
      "Epoch 142/1000\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.2094 - accuracy: 0.8690 - val_loss: 0.2123 - val_accuracy: 0.8360\n",
      "Epoch 143/1000\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 0.2091 - accuracy: 0.8650 - val_loss: 0.2124 - val_accuracy: 0.8350\n",
      "Epoch 144/1000\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.2090 - accuracy: 0.8780 - val_loss: 0.2119 - val_accuracy: 0.8330\n",
      "Epoch 145/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2090 - accuracy: 0.8650 - val_loss: 0.2117 - val_accuracy: 0.8390\n",
      "Epoch 146/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2087 - accuracy: 0.8600 - val_loss: 0.2112 - val_accuracy: 0.8390\n",
      "Epoch 147/1000\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.2083 - accuracy: 0.8700 - val_loss: 0.2113 - val_accuracy: 0.8450\n",
      "Epoch 148/1000\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.2080 - accuracy: 0.8830 - val_loss: 0.2107 - val_accuracy: 0.8470\n",
      "Epoch 149/1000\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.2079 - accuracy: 0.8590 - val_loss: 0.2106 - val_accuracy: 0.8350\n",
      "Epoch 150/1000\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.2078 - accuracy: 0.8650 - val_loss: 0.2105 - val_accuracy: 0.8460\n",
      "Epoch 151/1000\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.2074 - accuracy: 0.8740 - val_loss: 0.2103 - val_accuracy: 0.8350\n",
      "Epoch 152/1000\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.2073 - accuracy: 0.8720 - val_loss: 0.2100 - val_accuracy: 0.8530\n",
      "Epoch 153/1000\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.2070 - accuracy: 0.8720 - val_loss: 0.2099 - val_accuracy: 0.8450\n",
      "Epoch 154/1000\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.2070 - accuracy: 0.8740 - val_loss: 0.2100 - val_accuracy: 0.8450\n",
      "Epoch 155/1000\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.2067 - accuracy: 0.8640 - val_loss: 0.2098 - val_accuracy: 0.8350\n",
      "Epoch 156/1000\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.2065 - accuracy: 0.8890 - val_loss: 0.2093 - val_accuracy: 0.8350\n",
      "Epoch 157/1000\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 0.2063 - accuracy: 0.8790 - val_loss: 0.2095 - val_accuracy: 0.8490\n",
      "Epoch 158/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2060 - accuracy: 0.8700 - val_loss: 0.2090 - val_accuracy: 0.8490\n",
      "Epoch 159/1000\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.2058 - accuracy: 0.8890 - val_loss: 0.2085 - val_accuracy: 0.8430\n",
      "Epoch 160/1000\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.2057 - accuracy: 0.8800 - val_loss: 0.2086 - val_accuracy: 0.8360\n",
      "Epoch 161/1000\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.2054 - accuracy: 0.8680 - val_loss: 0.2085 - val_accuracy: 0.8500\n",
      "Epoch 162/1000\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 0.2052 - accuracy: 0.8790 - val_loss: 0.2084 - val_accuracy: 0.8410\n",
      "Epoch 163/1000\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.2052 - accuracy: 0.8800 - val_loss: 0.2080 - val_accuracy: 0.8450\n",
      "Epoch 164/1000\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.2053 - accuracy: 0.8700 - val_loss: 0.2080 - val_accuracy: 0.8570\n",
      "Epoch 165/1000\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.2048 - accuracy: 0.8850 - val_loss: 0.2078 - val_accuracy: 0.8520\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.2046 - accuracy: 0.8860 - val_loss: 0.2077 - val_accuracy: 0.8420\n",
      "Epoch 167/1000\n",
      "1000/1000 [==============================] - 0s 117us/step - loss: 0.2045 - accuracy: 0.8790 - val_loss: 0.2074 - val_accuracy: 0.8420\n",
      "Epoch 168/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 0.2048 - accuracy: 0.8760 - val_loss: 0.2077 - val_accuracy: 0.8480\n",
      "Epoch 169/1000\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 0.2047 - accuracy: 0.8570 - val_loss: 0.2075 - val_accuracy: 0.8250\n",
      "Epoch 170/1000\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.2040 - accuracy: 0.8850 - val_loss: 0.2071 - val_accuracy: 0.8410\n",
      "Epoch 171/1000\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 0.2038 - accuracy: 0.8750 - val_loss: 0.2069 - val_accuracy: 0.8530\n",
      "Epoch 172/1000\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 0.2038 - accuracy: 0.8840 - val_loss: 0.2063 - val_accuracy: 0.8500\n",
      "Epoch 173/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 0.2035 - accuracy: 0.8790 - val_loss: 0.2066 - val_accuracy: 0.8390\n",
      "Epoch 174/1000\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.2034 - accuracy: 0.8790 - val_loss: 0.2065 - val_accuracy: 0.8490\n",
      "Epoch 175/1000\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.2031 - accuracy: 0.8840 - val_loss: 0.2062 - val_accuracy: 0.8460\n",
      "Epoch 176/1000\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.2029 - accuracy: 0.8830 - val_loss: 0.2065 - val_accuracy: 0.8550\n",
      "Epoch 177/1000\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 0.2030 - accuracy: 0.8760 - val_loss: 0.2062 - val_accuracy: 0.8520\n",
      "Epoch 178/1000\n",
      "1000/1000 [==============================] - 0s 85us/step - loss: 0.2030 - accuracy: 0.8830 - val_loss: 0.2058 - val_accuracy: 0.8550\n",
      "Epoch 179/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 0.2029 - accuracy: 0.8770 - val_loss: 0.2059 - val_accuracy: 0.8490\n",
      "Epoch 180/1000\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.2025 - accuracy: 0.8840 - val_loss: 0.2058 - val_accuracy: 0.8570\n",
      "Epoch 181/1000\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 0.2024 - accuracy: 0.8830 - val_loss: 0.2054 - val_accuracy: 0.8410\n",
      "Epoch 182/1000\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 0.2022 - accuracy: 0.8780 - val_loss: 0.2054 - val_accuracy: 0.8480\n",
      "Epoch 183/1000\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.2021 - accuracy: 0.8840 - val_loss: 0.2052 - val_accuracy: 0.8490\n",
      "Epoch 184/1000\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.2022 - accuracy: 0.8650 - val_loss: 0.2053 - val_accuracy: 0.8410\n",
      "Epoch 185/1000\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 0.2019 - accuracy: 0.8810 - val_loss: 0.2053 - val_accuracy: 0.8620\n",
      "Epoch 186/1000\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.2017 - accuracy: 0.8860 - val_loss: 0.2046 - val_accuracy: 0.8510\n",
      "Epoch 187/1000\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.2016 - accuracy: 0.8880 - val_loss: 0.2046 - val_accuracy: 0.8530\n",
      "Epoch 188/1000\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 0.2014 - accuracy: 0.8810 - val_loss: 0.2049 - val_accuracy: 0.8420\n",
      "Epoch 189/1000\n",
      "1000/1000 [==============================] - 0s 103us/step - loss: 0.2017 - accuracy: 0.8730 - val_loss: 0.2044 - val_accuracy: 0.8510\n",
      "Epoch 190/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.2013 - accuracy: 0.8840 - val_loss: 0.2044 - val_accuracy: 0.8490\n",
      "Epoch 191/1000\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.2010 - accuracy: 0.8840 - val_loss: 0.2043 - val_accuracy: 0.8500\n",
      "Epoch 192/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 0.2011 - accuracy: 0.8870 - val_loss: 0.2041 - val_accuracy: 0.8550\n",
      "Epoch 193/1000\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.2013 - accuracy: 0.8890 - val_loss: 0.2042 - val_accuracy: 0.8390\n",
      "Epoch 194/1000\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.2011 - accuracy: 0.8740 - val_loss: 0.2041 - val_accuracy: 0.8500\n",
      "Epoch 195/1000\n",
      "1000/1000 [==============================] - 0s 110us/step - loss: 0.2008 - accuracy: 0.8860 - val_loss: 0.2040 - val_accuracy: 0.8410\n",
      "Epoch 196/1000\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 0.2008 - accuracy: 0.8810 - val_loss: 0.2042 - val_accuracy: 0.8550\n",
      "Epoch 197/1000\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.2004 - accuracy: 0.8920 - val_loss: 0.2039 - val_accuracy: 0.8540\n",
      "Epoch 198/1000\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 0.2004 - accuracy: 0.8830 - val_loss: 0.2037 - val_accuracy: 0.8510\n",
      "Epoch 199/1000\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.2002 - accuracy: 0.8920 - val_loss: 0.2035 - val_accuracy: 0.8540\n",
      "Epoch 200/1000\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.2001 - accuracy: 0.8910 - val_loss: 0.2035 - val_accuracy: 0.8640\n",
      "Epoch 201/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 0.2002 - accuracy: 0.8820 - val_loss: 0.2035 - val_accuracy: 0.8510\n",
      "Epoch 202/1000\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 0.2000 - accuracy: 0.8920 - val_loss: 0.2032 - val_accuracy: 0.8530\n",
      "Epoch 203/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 0.2000 - accuracy: 0.8910 - val_loss: 0.2032 - val_accuracy: 0.8460\n",
      "Epoch 204/1000\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.1998 - accuracy: 0.8980 - val_loss: 0.2029 - val_accuracy: 0.8490\n",
      "Epoch 205/1000\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.2001 - accuracy: 0.8820 - val_loss: 0.2032 - val_accuracy: 0.8470\n",
      "Epoch 206/1000\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.1998 - accuracy: 0.8870 - val_loss: 0.2031 - val_accuracy: 0.8520\n",
      "Epoch 207/1000\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.1995 - accuracy: 0.8690 - val_loss: 0.2030 - val_accuracy: 0.8550\n",
      "Epoch 208/1000\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.1994 - accuracy: 0.8940 - val_loss: 0.2031 - val_accuracy: 0.8540\n",
      "Epoch 209/1000\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.1992 - accuracy: 0.8940 - val_loss: 0.2029 - val_accuracy: 0.8500\n",
      "Epoch 210/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 0.1992 - accuracy: 0.8900 - val_loss: 0.2033 - val_accuracy: 0.8580\n",
      "Epoch 211/1000\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.1991 - accuracy: 0.8910 - val_loss: 0.2036 - val_accuracy: 0.8550\n",
      "Epoch 212/1000\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.1995 - accuracy: 0.8840 - val_loss: 0.2026 - val_accuracy: 0.8510\n",
      "Epoch 213/1000\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.1990 - accuracy: 0.8950 - val_loss: 0.2022 - val_accuracy: 0.8530\n",
      "Epoch 214/1000\n",
      "1000/1000 [==============================] - 0s 58us/step - loss: 0.1988 - accuracy: 0.8920 - val_loss: 0.2024 - val_accuracy: 0.8560\n",
      "Epoch 215/1000\n",
      "1000/1000 [==============================] - 0s 98us/step - loss: 0.1988 - accuracy: 0.8940 - val_loss: 0.2023 - val_accuracy: 0.8550\n",
      "Epoch 216/1000\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.1989 - accuracy: 0.8810 - val_loss: 0.2025 - val_accuracy: 0.8520\n",
      "Epoch 217/1000\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.1985 - accuracy: 0.8930 - val_loss: 0.2020 - val_accuracy: 0.8580\n",
      "Epoch 218/1000\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.1985 - accuracy: 0.8940 - val_loss: 0.2023 - val_accuracy: 0.8550\n",
      "Epoch 219/1000\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 0.1985 - accuracy: 0.8940 - val_loss: 0.2021 - val_accuracy: 0.8540\n",
      "Epoch 220/1000\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.1985 - accuracy: 0.8960 - val_loss: 0.2025 - val_accuracy: 0.8560\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.1985 - accuracy: 0.8920 - val_loss: 0.2024 - val_accuracy: 0.8610\n",
      "Epoch 222/1000\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.1982 - accuracy: 0.8950 - val_loss: 0.2021 - val_accuracy: 0.8450\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#early stopping : check loss value of testing dataset after every 5 epochs on training dataset\n",
    "#if the loss value increases, stop training\n",
    "early_stopping_monitor = EarlyStopping(patience=5)\n",
    "\n",
    "MLP = model.fit(input_training_set, output_training_set, epochs=1000, batch_size=50, validation_data = (input_testing_set, output_testing_set), callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting loss values on training dataset and testing dataset\n",
    "The model has an accuracy of 89.5% on training dataset and 85% on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f37d5952780>]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss = MLP.history['loss']\n",
    "plt.title(\"loss values of training dataset\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss value\")\n",
    "plt.plot(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f37d592d198>]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loss = MLP.history['val_loss']\n",
    "plt.title(\"loss values of training dataset\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss value\")\n",
    "plt.plot(test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_Python 3",
   "language": "python",
   "name": "jupyter3_python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
